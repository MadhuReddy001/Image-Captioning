{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJvAxGa5jZCh6q6l1hTNJv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadhuReddy001/Image-Captioning/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OJ7UBYuJC1M1",
        "outputId": "4fd2be73-0f24-457e-8dcf-3731afe00c2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.8.0 in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.68.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z1R6MghFC2IU",
        "outputId": "99fe8ad7-df49-4ca9-8f8c-7a7338e8bd06"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.6.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20.*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Tbr5tyDoC2L4",
        "outputId": "e83125fd-76ea-4929-e0c7-5a70109984aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf==3.20.* in /usr/local/lib/python3.10/dist-packages (3.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim.downloader as api\n",
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk import word_tokenize\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import pickle\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ycoeP-se_owi",
        "outputId": "4e7d0ee0-7f44-4e5a-e10a-1b2c6b90b056"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/sh/kpf9z73woodfssv/AAAw1_JIzpuVvwteJCma0xMla?dl=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "w_BRNn9VGcs1",
        "outputId": "e950e24f-5ea9-499a-cae2-f702115c5907"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-06 19:32:42--  https://www.dropbox.com/sh/kpf9z73woodfssv/AAAw1_JIzpuVvwteJCma0xMla?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fo/6cbk5ktsjhcd9kqxn01qj/AGuGEKF2SeUhJwGC4ju98vU?rlkey=25axzya0eum5h4qv91hpiies4&dl=0 [following]\n",
            "--2025-01-06 19:32:42--  https://www.dropbox.com/scl/fo/6cbk5ktsjhcd9kqxn01qj/AGuGEKF2SeUhJwGC4ju98vU?rlkey=25axzya0eum5h4qv91hpiies4&dl=0\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc894a5d33e4a8a8258a7c1e7553.dl.dropboxusercontent.com/zip_download_get/CFEtoUPgA9Q8wLvS9dgf2XhoMfH8ynrHS6cQEtrozjsHKvDMXRRZ8nXCBWUNx_NxPZf9Qarg2LtfwNyCWQm1u4VbzsULI7DH4RTccxTMpijEBQ# [following]\n",
            "--2025-01-06 19:32:43--  https://uc894a5d33e4a8a8258a7c1e7553.dl.dropboxusercontent.com/zip_download_get/CFEtoUPgA9Q8wLvS9dgf2XhoMfH8ynrHS6cQEtrozjsHKvDMXRRZ8nXCBWUNx_NxPZf9Qarg2LtfwNyCWQm1u4VbzsULI7DH4RTccxTMpijEBQ\n",
            "Resolving uc894a5d33e4a8a8258a7c1e7553.dl.dropboxusercontent.com (uc894a5d33e4a8a8258a7c1e7553.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc894a5d33e4a8a8258a7c1e7553.dl.dropboxusercontent.com (uc894a5d33e4a8a8258a7c1e7553.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 124207018 (118M) [application/zip]\n",
            "Saving to: ‘AAAw1_JIzpuVvwteJCma0xMla?dl=0’\n",
            "\n",
            "AAAw1_JIzpuVvwteJCm 100%[===================>] 118.45M  27.8MB/s    in 4.3s    \n",
            "\n",
            "2025-01-06 19:32:48 (27.9 MB/s) - ‘AAAw1_JIzpuVvwteJCma0xMla?dl=0’ saved [124207018/124207018]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filter = pd.read_csv(r'/content/AAAw1_JIzpuVvwteJCma0xMla?dl=0', sep=',', encoding='latin-1', header=1)\n",
        "df = pd.read_csv(r'/content/AAAw1_JIzpuVvwteJCma0xMla?dl=0', sep=',', encoding='latin-1', header=1)\n"
      ],
      "metadata": {
        "id": "fJRIoTQDD9cQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99FIQoQlHxrK",
        "outputId": "3f36cc1e-42cf-47db-f75d-5e3a29bd4869"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['\u000eBN', 'question_text', 'target'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filter.drop(columns=['\u000eBN'], inplace=True)\n",
        "filter.drop(index=[1306122, 1306123], inplace=True)"
      ],
      "metadata": {
        "id": "L65VnZhcHNzh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['question_text']\n",
        "Y = df['target']"
      ],
      "metadata": {
        "id": "S3NTzBhc_o99"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train.dropna().astype(int)),\n",
        "    y=y_train.dropna().astype(int)\n",
        ")"
      ],
      "metadata": {
        "id": "l7MioZwv_o6r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weight_dict = dict(enumerate(class_weights))"
      ],
      "metadata": {
        "id": "KrPvIpUY_pBH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype(str).apply(lambda x: x.lower() if isinstance(x, str) else '')\n",
        "x_test = x_test.astype(str).apply(lambda x: x.lower() if isinstance(x, str) else '')\n",
        "\n",
        "tk = Tokenizer(char_level=False, split=' ')\n",
        "tk.fit_on_texts(x_train)\n",
        "\n",
        "seq_train = tk.texts_to_sequences(x_train)\n",
        "seq_test = tk.texts_to_sequences(x_test)\n",
        "vocab_size = len(tk.word_index) + 1\n",
        "\n",
        "max_len = 44\n",
        "seq_train_matrix = sequence.pad_sequences(seq_train, maxlen=max_len)\n",
        "seq_test_matrix = sequence.pad_sequences(seq_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "68aA6vIr_pEl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqGM4q8s_6Ys",
        "outputId": "65faafe6-fb8a-4194-854c-03c4d2556a60"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tk.word_index.items():\n",
        "    if word in word2vec_model.key_to_index:\n",
        "        embedding_matrix[i] = word2vec_model[word]"
      ],
      "metadata": {
        "id": "VW_lDeiE_6cg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(name='text_input', shape=[max_len])\n",
        "embed = Embedding(vocab_size, embedding_dim, input_length=max_len, mask_zero=True,\n",
        "                  weights=[embedding_matrix], trainable=False)(inputs)\n",
        "lstm_layer = LSTM(512)(embed)\n",
        "drop1 = Dropout(0.2)(lstm_layer)\n",
        "dense1 = Dense(256, activation='relu')(drop1)\n",
        "drop2 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(128, activation='relu')(drop2)\n",
        "drop3 = Dropout(0.2)(dense2)\n",
        "dense3 = Dense(25, activation='relu')(drop3)\n",
        "drop4 = Dropout(0.2)(dense3)\n",
        "output = Dense(1, activation='sigmoid')(drop4)"
      ],
      "metadata": {
        "id": "0PK19ZVE_6f1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=inputs, outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "non_nan_indices = ~y_train.isna()\n",
        "seq_train_matrix = seq_train_matrix[non_nan_indices]\n",
        "y_train = y_train[non_nan_indices]\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "seq_train_matrix_resampled, y_train_resampled = ros.fit_resample(seq_train_matrix, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqOShZPkACxM",
        "outputId": "2bcd04a8-90a4-4003-efff-3e5fb1fdd717"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('/content/weights-{epoch:02d}-{val_loss:.4f}.keras',\n",
        "                             monitor='val_loss', verbose=1, save_best_only=True)\n",
        "earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "\n",
        "model.fit(seq_train_matrix_resampled, y_train_resampled, epochs=15, batch_size=1000,\n",
        "          validation_data=(seq_test_matrix, y_test), callbacks=[earlystop, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydhV4O4wAC0x",
        "outputId": "3cf4bf65-9ce0-498b-ff73-246d8a5f529b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            " 218/1961 [==>...........................] - ETA: 4:53:42 - loss: 0.3403 - accuracy: 0.8624"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model('/content/weights-04-0.2007.keras')\n",
        "best_model_weights = best_model.get_weights()"
      ],
      "metadata": {
        "id": "D8SC0qWyAC38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(name='text_input', shape=[max_len])\n",
        "embed = Embedding(vocab_size, embedding_dim, input_length=max_len, mask_zero=True,\n",
        "                  weights=[embedding_matrix], trainable=False)(inputs)\n",
        "lstm_layer = LSTM(512)(embed)\n",
        "drop1 = Dropout(0.2)(lstm_layer)\n",
        "dense1 = Dense(256, activation='relu')(drop1)\n",
        "drop2 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(128, activation='relu')(drop2)\n",
        "drop3 = Dropout(0.2)(dense2)\n",
        "dense3 = Dense(25, activation='relu')(drop3)\n",
        "drop4 = Dropout(0.2)(dense3)\n",
        "output = Dense(1, activation='sigmoid')(drop4)"
      ],
      "metadata": {
        "id": "ftWoKS9RALPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recreated_model = Model(inputs=inputs, outputs=output)\n",
        "recreated_model.set_weights(best_model_weights)\n",
        "\n",
        "p = recreated_model.predict(seq_test_matrix)\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, p))"
      ],
      "metadata": {
        "id": "KJerV-JiTLMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tk, f)\n",
        "model.save('text_classification_model.keras')"
      ],
      "metadata": {
        "id": "p93_SevQALSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_question = \"What is the capital of France?\"\n",
        "\n",
        "example_question = example_question.lower()\n",
        "\n",
        "example_sequence = tk.texts_to_sequences([example_question])\n",
        "\n",
        "example_padded = sequence.pad_sequences(example_sequence, maxlen=max_len)\n",
        "\n",
        "prediction = recreated_model.predict(example_padded)\n",
        "\n",
        "print(\"Prediction:\", prediction)\n",
        "print(\"Class:\", \"Positive\" if prediction[0][0] > 0.5 else \"Negative\")\n"
      ],
      "metadata": {
        "id": "CQyZxze0ALWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_question(model, tokenizer, question, max_len):\n",
        "\n",
        "    question = question.lower()\n",
        "    sequence = tokenizer.texts_to_sequences([question])\n",
        "    padded_sequence = sequence.pad_sequences(sequence, maxlen=max_len)\n",
        "\n",
        "    prediction = model.predict(padded_sequence)[0][0]\n",
        "\n",
        "    return prediction, \"Positive\" if prediction > 0.5 else \"Negative\"\n",
        "\n",
        "example_question = \"What is the capital of France?\"\n",
        "probability, predicted_class = predict_question(recreated_model, tk, example_question, max_len)\n",
        "\n",
        "print(f\"Prediction: {probability}\")\n",
        "print(f\"Class: {predicted_class}\")"
      ],
      "metadata": {
        "id": "Sl6NnikMAiQy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}